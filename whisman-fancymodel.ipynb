{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** I didn't port over the data from the original [Kaggle competition  ](https://www.kaggle.com/competitions/csci-4622-spring-22). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-01T21:28:53.870600Z",
     "iopub.status.busy": "2022-04-01T21:28:53.863726Z",
     "iopub.status.idle": "2022-04-01T21:29:00.259433Z",
     "shell.execute_reply": "2022-04-01T21:29:00.259848Z",
     "shell.execute_reply.started": "2022-04-01T19:02:50.761545Z"
    },
    "papermill": {
     "duration": 6.414008,
     "end_time": "2022-04-01T21:29:00.260099",
     "exception": false,
     "start_time": "2022-04-01T21:28:53.846091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "import keras.layers\n",
    "import keras.utils.all_utils as kr_utils\n",
    "import keras.regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.291413Z",
     "iopub.status.busy": "2022-04-01T21:29:00.289784Z",
     "iopub.status.idle": "2022-04-01T21:29:00.291991Z",
     "shell.execute_reply": "2022-04-01T21:29:00.292437Z",
     "shell.execute_reply.started": "2022-04-01T19:02:58.102600Z"
    },
    "papermill": {
     "duration": 0.019313,
     "end_time": "2022-04-01T21:29:00.292563",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.273250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images_folder = \"/kaggle/input/csci-4622-spring-22/train/train/\"\n",
    "test_images_folder = \"/kaggle/input/csci-4622-spring-22/test/test/\"\n",
    "train_csv = \"/kaggle/input/csci-4622-spring-22/train.csv\"\n",
    "submission_csv = \"/kaggle/input/csci-4622-spring-22/sample_submission.csv\"\n",
    "patch_size = 192\n",
    "num_classes = 53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.329933Z",
     "iopub.status.busy": "2022-04-01T21:29:00.328330Z",
     "iopub.status.idle": "2022-04-01T21:29:00.330568Z",
     "shell.execute_reply": "2022-04-01T21:29:00.330966Z",
     "shell.execute_reply.started": "2022-04-01T19:02:58.111565Z"
    },
    "papermill": {
     "duration": 0.026045,
     "end_time": "2022-04-01T21:29:00.331094",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.305049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RockGenerator(kr_utils.Sequence):\n",
    "    def __init__(self, df, # contains the images names and their labels\n",
    "                 path_to_images,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True, # to shuffle the data at the end of each epoch\n",
    "                ):\n",
    "        \n",
    "        self.df = df # dataframe with two columns \"image\" and \"label\"\n",
    "        self.images_path = path_to_images\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.mean = 125.3\n",
    "        self.std = 63.5\n",
    "        if shuffle:\n",
    "            self.indexes = np.random.permutation(self.df.shape[0])\n",
    "        else:\n",
    "            self.indexes = np.arange(self.df.shape[0])\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self): # called at the end of each epoch\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        # return number of batches in dataset / steps per epoch\n",
    "        return int(np.ceil(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get batch at position index\n",
    "        indexes = self.df.index[self.indexes[index*self.batch_size:min((index+1)*self.batch_size, self.df.shape[0])] ] \n",
    "        images = np.zeros((len(indexes), patch_size, patch_size,3))\n",
    "        labels = np.zeros((len(indexes), num_classes))\n",
    "        for i, ind in enumerate(indexes):\n",
    "            image = np.asarray(Image.open(os.path.join(self.images_path , \"{}.png\".format(self.df.image[ind]))))\n",
    "            image = (image - self.mean) / self.std # this is global mean and std, you can use mean/std per channel\n",
    "            images[i] = image\n",
    "            labels[i] = kr_utils.to_categorical(self.df.label[ind], num_classes=num_classes) # gives the one-hot-encoding\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.386099Z",
     "iopub.status.busy": "2022-04-01T21:29:00.385548Z",
     "iopub.status.idle": "2022-04-01T21:29:00.421083Z",
     "shell.execute_reply": "2022-04-01T21:29:00.420605Z",
     "shell.execute_reply.started": "2022-04-01T19:02:58.149544Z"
    },
    "papermill": {
     "duration": 0.052017,
     "end_time": "2022-04-01T21:29:00.421198",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.369181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(pd.read_csv(train_csv), test_size = 0.1, random_state = 5622)\n",
    "df_test = pd.read_csv(submission_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.452420Z",
     "iopub.status.busy": "2022-04-01T21:29:00.451706Z",
     "iopub.status.idle": "2022-04-01T21:29:00.453874Z",
     "shell.execute_reply": "2022-04-01T21:29:00.454236Z",
     "shell.execute_reply.started": "2022-04-01T19:02:58.201308Z"
    },
    "papermill": {
     "duration": 0.020096,
     "end_time": "2022-04-01T21:29:00.454394",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.434298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = RockGenerator(df_train, train_images_folder)\n",
    "val_generator = RockGenerator(df_val, train_images_folder, shuffle=False)\n",
    "test_generator = RockGenerator(df_test, test_images_folder, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.484072Z",
     "iopub.status.busy": "2022-04-01T21:29:00.482915Z",
     "iopub.status.idle": "2022-04-01T21:29:00.486674Z",
     "shell.execute_reply": "2022-04-01T21:29:00.486200Z",
     "shell.execute_reply.started": "2022-04-01T19:02:58.213894Z"
    },
    "papermill": {
     "duration": 0.019957,
     "end_time": "2022-04-01T21:29:00.486781",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.466824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = RockGenerator(df_train, train_images_folder)\n",
    "val_generator = RockGenerator(df_val, train_images_folder, shuffle=False)\n",
    "test_generator = RockGenerator(df_test, test_images_folder, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012128,
     "end_time": "2022-04-01T21:29:00.356765",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.344637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## My models are seen below\n",
    "I kept my first idea in the next markdown cell. \n",
    "\n",
    "Parallel Neural Nets\n",
    "\n",
    "```\n",
    "Run through some convolutions\n",
    "           |\n",
    "        flatten\n",
    "       /       \\\n",
    "  two Feed Foreward \n",
    "  NNs with different activations\n",
    "     \\         /\n",
    "       combine (Average maybe)\n",
    "          |\n",
    "        \n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T02:41:03.642299Z",
     "iopub.status.busy": "2022-03-31T02:41:03.64199Z",
     "iopub.status.idle": "2022-03-31T02:41:04.033007Z",
     "shell.execute_reply": "2022-03-31T02:41:04.032112Z",
     "shell.execute_reply.started": "2022-03-31T02:41:03.642267Z"
    },
    "papermill": {
     "duration": 0.011983,
     "end_time": "2022-04-01T21:29:00.511117",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.499134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```\n",
    "inputLayer = keras.Input(shape=(patch_size,patch_size,3))\n",
    "\n",
    "\n",
    "gauss = keras.layers.GaussianNoise(stddev=0.1)(inputLayer)\n",
    "# convolute and pool 3 times layers\n",
    "# each using a 25x25 convolution matrix   \n",
    "# now with a swish activation\n",
    "cLayer1 = keras.layers.Conv2D(100, kernel_size=(25,25), kernel_regularizer=\"L2\", activation=tf.nn.silu)(gauss)\n",
    "poolLayer1 = keras.layers.MaxPooling2D(2,2)(cLayer1)\n",
    "\n",
    "cLayer2 = keras.layers.Conv2D(100, kernel_size=(25,25),kernel_regularizer=\"L2\", activation=tf.nn.silu)(poolLayer1)\n",
    "poolLayer2 = keras.layers.MaxPooling2D(2,2)(cLayer2)\n",
    "\n",
    "cLayer3 = keras.layers.Conv2D(200, kernel_size=(25,25), kernel_regularizer=\"L2\", activation=tf.nn.silu)(poolLayer2)\n",
    "poolLayer3 = keras.layers.MaxPooling2D(2,2)(cLayer3)\n",
    "\n",
    "flatten_layer = keras.layers.Flatten()(poolLayer3)\n",
    "\n",
    "'''\n",
    "dLayer = keras.layers.Dense(250, kernel_regularizer = \"L2\", activation = tf.nn.silu)(gauss)\n",
    "dLayer2 = keras.layers.Dense(250, kernel_regularizer = \"L2\", activation = tf.nn.silu)(dLayer)\n",
    "output_layer = keras.layers.Dense(53)(dLayer2)\n",
    "'''\n",
    "#  give the flattened results to 3 different FFs each with their own activation function\n",
    "activations = ['sigmoid','tanh','relu']\n",
    "out_layers = []\n",
    "for i, activation in enumerate(activations):\n",
    "    #gauss = keras.layers.GaussianNoise(stddev=0.1)(flatten_layer)\n",
    "    \n",
    "    a_layer3 = keras.layers.Dense(1500, kernel_regularizer = \"L2\", activation=activation, name = \"{}_layer1\".format(activation))(flatten_layer)\n",
    "    a_layer2 = keras.layers.Dense(1000, kernel_regularizer = \"L2\", activation=activation, name = \"{}_layer2\".format(activation))(a_layer3)\n",
    "    a_layer = keras.layers.Dense(500, kernel_regularizer = \"L2\", activation=activation, name = \"{}_layer3\".format(activation))(a_layer2)\n",
    "    \n",
    "    a_out = keras.layers.Dense(100, kernel_regularizer = \"L2\", activation = activation, name = \"{}_out\".format(activation))(a_layer)\n",
    "    out_layers.append(a_out)\n",
    "\n",
    "# concatenate the results of the different FFs\n",
    "recombine = keras.layers.Concatenate()(out_layers)\n",
    "\n",
    "\n",
    "# feed it to the output layer\n",
    "output_layer = keras.layers.Dense(53)(recombine)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=inputLayer,outputs = output_layer)\n",
    "\n",
    "# show a model summary\n",
    "model.summary()\n",
    "\n",
    "kr_utils.plot_model(model)\n",
    "```\n",
    "\n",
    "# Model 2 use inception V3 as a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:00.543888Z",
     "iopub.status.busy": "2022-04-01T21:29:00.543373Z",
     "iopub.status.idle": "2022-04-01T21:29:05.412624Z",
     "shell.execute_reply": "2022-04-01T21:29:05.411725Z",
     "shell.execute_reply.started": "2022-04-01T21:01:57.189162Z"
    },
    "papermill": {
     "duration": 4.889166,
     "end_time": "2022-04-01T21:29:05.412761",
     "exception": false,
     "start_time": "2022-04-01T21:29:00.523595",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 21:29:00.635815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:00.726650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:00.727380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:00.728572: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-01 21:29:00.730329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:00.730979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:00.731594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:02.693635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:02.694431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:02.695073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-01 21:29:02.695666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "87924736/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# start with a base model of Inception V3\n",
    "Base_model = keras.applications.inception_v3.InceptionV3(input_shape=(patch_size,patch_size,3),include_top=False)\n",
    "\n",
    "Base_output = Base_model.output\n",
    "\n",
    "# connect it into a global Average pooling layer (I named it MY_FIRST_INCLUSION just so that its easier)\n",
    "layer1 = keras.layers.GlobalAveragePooling2D(name=\"Final_Pool\")(Base_output)\n",
    "\n",
    "# connect that into a fully connected dense FF layer that uses swish as the activation \n",
    "# (to avoid vanishing gradient problem and because I just think its a cool activation function)\n",
    "next_layer = keras.layers.Dense(2048, activation=tf.nn.silu, kernel_regularizer=\"l2\", name = \"Swishy_swish\")(layer1)\n",
    "# send that into a final output layer to make the final calcualtion\n",
    "output_layer = keras.layers.Dense(53)(next_layer)\n",
    "\n",
    "model = keras.Model(inputs=Base_model.input, outputs=output_layer)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:05.454187Z",
     "iopub.status.busy": "2022-04-01T21:29:05.453316Z",
     "iopub.status.idle": "2022-04-01T21:29:05.471468Z",
     "shell.execute_reply": "2022-04-01T21:29:05.471854Z",
     "shell.execute_reply.started": "2022-04-01T21:02:00.154266Z"
    },
    "papermill": {
     "duration": 0.042609,
     "end_time": "2022-04-01T21:29:05.471983",
     "exception": false,
     "start_time": "2022-04-01T21:29:05.429374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), # this means that the network returns the log probabilities and not probas\n",
    "              optimizer=keras.optimizers.adam_v2.Adam(learning_rate=4e-5), # The optimizer that smooths the gradient\n",
    "              metrics=[\"accuracy\", \n",
    "                       tfa.metrics.F1Score(num_classes=num_classes,average=\"macro\", name=\"macroF1\")]) # We want to track accuracy and MacroF1\n",
    "checkpoint_callbk = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"fancy_inception_model3\", # name of file to save the best model to\n",
    "    monitor=\"val_macroF1\", # prefix val to specify that we want the model with best macroF1 on the validation data\n",
    "    verbose=1, # prints out when the model achieve a better epoch\n",
    "    mode=\"max\", # the monitored metric should be maximized\n",
    "    save_freq=\"epoch\", # clear\n",
    "    save_best_only=True, # of course, if not, every time a new best is achieved will be savedf differently\n",
    "    save_weights_only=True # this means that we don't have to save the architecture, if you change the architecture, you'll loose the old weights\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:29:05.511361Z",
     "iopub.status.busy": "2022-04-01T21:29:05.510668Z",
     "iopub.status.idle": "2022-04-01T21:41:58.856440Z",
     "shell.execute_reply": "2022-04-01T21:41:58.856889Z"
    },
    "papermill": {
     "duration": 773.368668,
     "end_time": "2022-04-01T21:41:58.857066",
     "exception": false,
     "start_time": "2022-04-01T21:29:05.488398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 21:29:05.873351: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 21:29:13.577781: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425/425 [==============================] - 137s 291ms/step - loss: 19.1790 - accuracy: 0.2514 - macroF1: 0.2111 - val_loss: 14.6706 - val_accuracy: 0.4318 - val_macroF1: 0.3924\n",
      "\n",
      "Epoch 00001: val_macroF1 improved from -inf to 0.39236, saving model to fancy_inception_model3\n",
      "Epoch 2/10\n",
      "425/425 [==============================] - 67s 157ms/step - loss: 11.7962 - accuracy: 0.5754 - macroF1: 0.5520 - val_loss: 9.4933 - val_accuracy: 0.6066 - val_macroF1: 0.5957\n",
      "\n",
      "Epoch 00002: val_macroF1 improved from 0.39236 to 0.59571, saving model to fancy_inception_model3\n",
      "Epoch 3/10\n",
      "425/425 [==============================] - 65s 152ms/step - loss: 7.4322 - accuracy: 0.7766 - macroF1: 0.7728 - val_loss: 6.2565 - val_accuracy: 0.7007 - val_macroF1: 0.7063\n",
      "\n",
      "Epoch 00003: val_macroF1 improved from 0.59571 to 0.70630, saving model to fancy_inception_model3\n",
      "Epoch 4/10\n",
      "425/425 [==============================] - 65s 153ms/step - loss: 4.6902 - accuracy: 0.8678 - macroF1: 0.8750 - val_loss: 4.1543 - val_accuracy: 0.7364 - val_macroF1: 0.7482\n",
      "\n",
      "Epoch 00004: val_macroF1 improved from 0.70630 to 0.74818, saving model to fancy_inception_model3\n",
      "Epoch 5/10\n",
      "425/425 [==============================] - 66s 155ms/step - loss: 2.9396 - accuracy: 0.8992 - macroF1: 0.9109 - val_loss: 2.8496 - val_accuracy: 0.7523 - val_macroF1: 0.7661\n",
      "\n",
      "Epoch 00005: val_macroF1 improved from 0.74818 to 0.76609, saving model to fancy_inception_model3\n",
      "Epoch 6/10\n",
      "425/425 [==============================] - 66s 154ms/step - loss: 1.8459 - accuracy: 0.9088 - macroF1: 0.9217 - val_loss: 1.9919 - val_accuracy: 0.7583 - val_macroF1: 0.7720\n",
      "\n",
      "Epoch 00006: val_macroF1 improved from 0.76609 to 0.77196, saving model to fancy_inception_model3\n",
      "Epoch 7/10\n",
      "425/425 [==============================] - 65s 153ms/step - loss: 1.1612 - accuracy: 0.9194 - macroF1: 0.9337 - val_loss: 1.4837 - val_accuracy: 0.7503 - val_macroF1: 0.7645\n",
      "\n",
      "Epoch 00007: val_macroF1 did not improve from 0.77196\n",
      "Epoch 8/10\n",
      "425/425 [==============================] - 65s 154ms/step - loss: 0.7827 - accuracy: 0.9192 - macroF1: 0.9338 - val_loss: 1.1921 - val_accuracy: 0.7589 - val_macroF1: 0.7765\n",
      "\n",
      "Epoch 00008: val_macroF1 improved from 0.77196 to 0.77646, saving model to fancy_inception_model3\n",
      "Epoch 9/10\n",
      "425/425 [==============================] - 66s 154ms/step - loss: 0.5645 - accuracy: 0.9219 - macroF1: 0.9363 - val_loss: 1.0074 - val_accuracy: 0.7768 - val_macroF1: 0.7934\n",
      "\n",
      "Epoch 00009: val_macroF1 improved from 0.77646 to 0.79340, saving model to fancy_inception_model3\n",
      "Epoch 10/10\n",
      "425/425 [==============================] - 66s 155ms/step - loss: 0.4485 - accuracy: 0.9233 - macroF1: 0.9370 - val_loss: 0.9603 - val_accuracy: 0.7742 - val_macroF1: 0.7867\n",
      "\n",
      "Epoch 00010: val_macroF1 did not improve from 0.79340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f996c0a97d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,callbacks=[checkpoint_callbk], epochs=10, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T02:02:27.388585Z",
     "iopub.status.busy": "2022-03-31T02:02:27.387931Z",
     "iopub.status.idle": "2022-03-31T02:24:23.720789Z",
     "shell.execute_reply": "2022-03-31T02:24:23.720075Z",
     "shell.execute_reply.started": "2022-03-31T02:02:27.38855Z"
    },
    "papermill": {
     "duration": 1.333321,
     "end_time": "2022-04-01T21:42:01.565402",
     "exception": false,
     "start_time": "2022-04-01T21:42:00.232081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T21:42:04.330432Z",
     "iopub.status.busy": "2022-04-01T21:42:04.310030Z",
     "iopub.status.idle": "2022-04-01T21:42:24.437030Z",
     "shell.execute_reply": "2022-04-01T21:42:24.436368Z",
     "shell.execute_reply.started": "2022-03-31T02:25:40.872187Z"
    },
    "papermill": {
     "duration": 21.529192,
     "end_time": "2022-04-01T21:42:24.437186",
     "exception": false,
     "start_time": "2022-04-01T21:42:02.907994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"fancy_inception_model3\")\n",
    "\n",
    "y_hat = model.predict(test_generator) # logits of the 53 classes\n",
    "y_hat = np.argmax(y_hat, axis=1) # take the classe with the higher logit\n",
    "test_generator.df.label = y_hat\n",
    "test_generator.df.to_csv(\"submission.csv\", index=False) # we don't want to add the column of indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.564116,
     "end_time": "2022-04-01T21:42:27.351429",
     "exception": false,
     "start_time": "2022-04-01T21:42:25.787313",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 826.094524,
   "end_time": "2022-04-01T21:42:31.713824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-01T21:28:45.619300",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
